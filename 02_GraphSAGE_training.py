#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Sep 14 22:56:40 2022

@author: tongliu
"""

"""# Specify the parameter values"""

number_of_walks = 1    # the number of walks to take per node
length = 11
num_samples = [20,11]
dim = 220
batch_size = 256
epochs = 200
lr = 12e-4
patience = 5
RANDOM_SEED_1 = 1234
RANDOM_SEED_2 = 123
RANDOM_SEED_3 = 42

# Load the Packages
import tensorflow as tf
from keras.backend import set_session
import random
import numpy as np
import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt

from tqdm import tqdm
from scipy.spatial import cKDTree as KDTree
from tensorflow.keras.utils import to_categorical
from tensorflow import keras

import stellargraph as sg
from stellargraph.data import EdgeSplitter
from stellargraph.mapper import GraphSAGELinkGenerator
from stellargraph.layer import GraphSAGE, link_classification
from stellargraph.layer.graphsage import MaxPoolingAggregator, MeanPoolingAggregator,AttentionalAggregator
from stellargraph.data import UniformRandomWalk
from stellargraph.data import UnsupervisedSampler

from sklearn.model_selection import train_test_split
from sklearn import preprocessing, feature_extraction, model_selection
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import accuracy_score
from stellargraph import globalvar
from stellargraph.mapper import GraphSAGENodeGenerator

import os, datetime
from pytz import timezone

# Generate Reproducible Results
random.seed(RANDOM_SEED_1)      # core Python generated random numbers
np.random.seed(RANDOM_SEED_2)   # Numpy generated random numbers
tf.random.set_seed(RANDOM_SEED_3)   # TensorFlow generated random numbers

# Force TensorFlow to use single thread
session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)
set_session(sess)

# Track the current time for naming result files
current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

"""# Create the graph"""

input_edges = pd.read_csv("data/Input_Edges_LasVegas_LST.csv", index_col=0)
input_edges.columns = ['source', 'target','weight']
input_nodes = pd.read_csv('data/Input_Node_Features_LasVegas_LST.csv',header=None, index_col=None)
G = sg.StellarGraph(
    {"corner": input_nodes}, {"line": input_edges}
)
print(G.info())

"""# Build the GraphSAGE Model"""

# Specify nodes for Unsupervised Sampler
nodes = list(G.nodes())

# Create Unsupervised Sampler.
unsupervised_samples = UnsupervisedSampler(
    G, nodes=nodes, length=length, number_of_walks=number_of_walks
)

# Create a node pair gengerator (map the pairs of nodes generated by Unsupervised Sampler)
generator = GraphSAGELinkGenerator(G, batch_size, num_samples, weighted=True)
train_gen = generator.flow(unsupervised_samples,seed=RANDOM_SEED_3)
layer_sizes = [dim, dim]
graphsage = GraphSAGE(
    layer_sizes=layer_sizes, generator=generator,
   # aggregator=AttentionalAggregator,
   # aggregator=MeanPoolingAggregator,
    aggregator=MaxPoolingAggregator,
    bias=True, dropout=0.0, normalize="l2"
)

# Build the model and expose input and output sockets of graphsage, for node pair inputs:
x_inp, x_out = graphsage.in_out_tensors()

prediction = link_classification(
    output_dim=1, output_act="sigmoid", edge_embedding_method="ip"  # 'ip' for inner product
)(x_out)

# create model save name
modeldir = os.path.join("Models", current_time)
modelname = modeldir + "_model.h5"

earlystop = tf.keras.callbacks.EarlyStopping(
    monitor='loss', mode='min', verbose=1, patience=patience)

model = keras.Model(inputs=x_inp, outputs=prediction)
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=lr), 
    loss=keras.losses.binary_crossentropy,
    metrics=[keras.metrics.binary_accuracy]
)
#model.summary()

"""# Model Training"""

history = model.fit(
    train_gen,
    epochs=epochs,
    verbose=1,
    use_multiprocessing=True,
    workers=12,
    shuffle=True,
    callbacks=[earlystop])

model.save(modelname)
print(modelname, " model saved.")

"""# Extract Node Embeddings"""

# Get the embedding model
x_inp_src = x_inp[0::2]
x_out_src = x_out[0]
embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)

# We want to evaluate node embeddings for all nodes in the graph.
node_ids = input_nodes.index
node_gen = GraphSAGENodeGenerator(G, batch_size, num_samples, seed=RANDOM_SEED_3).flow(node_ids)
node_embeddings = embedding_model.predict(node_gen, workers=12, verbose=1)
node_embeddings.shape

# Save the node embeddings
def gf_name(number_of_walks,length):
  f1 = '{:01d}'.format(number_of_walks)
  f2 = '{:01d}'.format(length)
  name = "_wlk-"+f1+"_len-"+f2+"_embeddings.npy"
  return name

dir = os.path.join("Results", current_time)
filename = dir+gf_name(number_of_walks, length)
print(filename)
np.save(filename, node_embeddings)
print(filename, " SUCCESSFULLY SAVED.")
print("\nLearning rate: ", lr)
print("\nPatince: ", patience)
